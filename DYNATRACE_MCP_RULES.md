# Dynatrace Managed MCP Server - AI Assistant Rules

## Core Operational Rules

### üîí Security & Privacy Rules

1. **NEVER** expose API tokens, credentials, or sensitive authentication data
2. **ALWAYS** sanitize sensitive information from responses (IP addresses, internal hostnames)
3. **AVOID** sharing confidential business metrics or performance data
4. **REDACT** personal information from audit logs or comments
5. **WARN** users when requesting potentially sensitive data

### üõ°Ô∏è Data Protection Rules

1. **MASK** production system names and identifiers when sharing examples
2. **ANONYMIZE** entity names that could reveal business information
3. **FILTER** out proprietary metrics or custom business KPIs
4. **LIMIT** audit log details that could expose security practices
5. **PROTECT** vulnerability details that could be exploited

### ‚öôÔ∏è Tool Usage Rules

#### Problem Management

- **ALWAYS** check problem status before attempting modifications
- **REQUIRE** context when adding comments to problems
- **VERIFY** problem IDs exist before commenting operations
- **LIMIT** comment operations to necessary business justification
- **PRESERVE** existing problem state unless explicitly requested

#### Entity Operations

- **VALIDATE** entity selectors before querying
- **LIMIT** entity queries to reasonable scopes (avoid broad wildcards)
- **RESPECT** entity type constraints in selectors
- **COMBINE** multiple entity queries efficiently
- **CACHE** entity relationship data when possible

#### Metrics & Performance

- **RESTRICT** time ranges to reasonable periods (avoid excessive historical data)
- **OPTIMIZE** metric queries with appropriate resolution
- **BATCH** related metric queries when possible
- **VALIDATE** metric selectors before querying
- **EXPLAIN** metric transformations and aggregations

#### Event Management

- **FILTER** events by relevant time ranges
- **CORRELATE** events with other monitoring data
- **AVOID** using broken event property tools (known 404 issues)
- **PRIORITIZE** event severity in analysis
- **CONTEXTUALIZE** events with entity relationships

### üîß Technical Rules

#### Query Optimization

1. **USE** entity selectors to limit scope: `type("HOST")` not `entitySelector("")`
2. **SPECIFY** reasonable page sizes: 10-50 for exploration, larger for reports
3. **IMPLEMENT** proper time range filters: `from="now-1h"` not unlimited ranges
4. **LEVERAGE** pagination for large datasets with `nextPageKey`
5. **COMBINE** related queries to minimize API calls

#### Error Handling

1. **RETRY** rate-limited requests (429) with exponential backoff
2. **VALIDATE** parameters before making API calls
3. **HANDLE** 404 errors gracefully (entity not found)
4. **EXPLAIN** permission errors (403) with suggested solutions
5. **FALLBACK** to alternative tools when primary tools fail

#### Response Processing

1. **PARSE** JSON responses completely before analysis
2. **EXTRACT** key information from nested response structures
3. **CORRELATE** related data points across multiple responses
4. **SUMMARIZE** large datasets with key insights
5. **FORMAT** timestamps in human-readable format

### üìä Data Analysis Rules

#### Problem Analysis

- **CORRELATE** problems with affected entities and metrics
- **ANALYZE** problem evidence and impact details
- **TIMELINE** problem events chronologically
- **IDENTIFY** root cause indicators in evidence
- **RECOMMEND** specific remediation actions

#### Performance Analysis

- **BASELINE** current metrics against historical data
- **IDENTIFY** anomalies and trends in metric data
- **CORRELATE** performance issues with system events
- **CALCULATE** performance deltas and rates of change
- **THRESHOLD** analysis against known performance limits

#### Infrastructure Analysis

- **MAP** entity relationships and dependencies
- **INVENTORY** monitored components systematically
- **CLASSIFY** entities by type, environment, and function
- **ASSESS** monitoring coverage and gaps
- **RECOMMEND** monitoring improvements

### üö® Known Issue Rules

#### Schema Validation Issues

- **AVOID** using `add_tags` and `delete_tags` (schema errors)
- **SKIP** `ingest_event` unless attachRules can be properly defined
- **DOCUMENT** workarounds for broken tools
- **SUGGEST** alternative approaches for failed operations

#### API Endpoint Issues

- **BYPASS** `list_event_properties` and `get_event_property` (404 errors)
- **USE** alternative event analysis methods
- **INFORM** users of API limitations
- **SUGGEST** manual investigation for missing capabilities

### üéØ Response Formatting Rules

#### Information Architecture

1. **STRUCTURE** responses with clear headings and sections
2. **PRIORITIZE** critical information first
3. **SUMMARIZE** key findings before detailed analysis
4. **LINK** related information across different tool outputs
5. **CONCLUDE** with actionable recommendations

#### Data Presentation

1. **TABLE** format for comparative data
2. **LIST** format for inventories and catalogs
3. **TIMELINE** format for chronological data
4. **TREE** format for hierarchical relationships
5. **METRICS** format for quantitative analysis

#### User Guidance

1. **EXPLAIN** tool selection rationale
2. **DESCRIBE** query parameters and filters used
3. **INTERPRET** raw API responses in business context
4. **SUGGEST** follow-up actions and investigations
5. **EDUCATE** users on Dynatrace concepts and terminology

### üîÑ Workflow Rules

#### Investigation Workflows

1. **START** with broad discovery (`list_problems`, `list_entities`)
2. **FOCUS** on specific items with detail tools (`get_problem`, `get_entity`)
3. **CORRELATE** findings across multiple data sources
4. **ANALYZE** trends and patterns in historical data
5. **DOCUMENT** findings and recommendations

#### Monitoring Workflows

1. **ESTABLISH** baseline performance metrics
2. **MONITOR** key performance indicators regularly
3. **ALERT** on threshold violations and anomalies
4. **INVESTIGATE** performance degradations systematically
5. **OPTIMIZE** monitoring coverage and efficiency

#### Collaboration Workflows

1. **DOCUMENT** investigation findings in problem comments
2. **SHARE** relevant data with team members
3. **TRACK** problem resolution progress
4. **MAINTAIN** audit trail of investigative actions
5. **FOLLOW** up on recommended actions

### ‚ö†Ô∏è Warning Rules

#### High-Risk Operations

- **WARN** before closing problems (`close_problem`)
- **CONFIRM** before deleting metrics (`delete_metric`)
- **VALIDATE** before modifying problem comments
- **AUTHENTICATE** destructive operations with user confirmation

#### Data Sensitivity

- **ALERT** when accessing audit logs with sensitive information
- **CAUTION** when viewing vulnerability details
- **PROTECT** when sharing system configuration data
- **MASK** when displaying authentication or token information

#### Performance Impact

- **LIMIT** concurrent API calls to prevent rate limiting
- **OPTIMIZE** large data queries to minimize system impact
- **BATCH** operations when possible to reduce API load
- **SCHEDULE** intensive operations during off-peak hours

## Environment-Specific Rules

### Lab Environment Considerations

- **RECOGNIZE** this is a lab/demo environment (lab.dt-transform.com)
- **ALLOW** more exploratory queries than in production
- **USE** for learning and testing purposes
- **DOCUMENT** findings for knowledge sharing
- **EXPERIMENT** with different query patterns

### Known Infrastructure

- **LEVERAGE** knowledge of Azure Kubernetes environment
- **FOCUS** on easytrade cluster for Kubernetes analysis
- **CORRELATE** synthetic monitor issues with external dependencies
- **CONSIDER** VM scale set architecture in host analysis

## Compliance & Governance

### Audit Requirements

1. **LOG** all API operations for audit trail
2. **DOCUMENT** data access and modifications
3. **MAINTAIN** records of investigation activities
4. **REPORT** security-relevant discoveries
5. **COMPLY** with organizational data policies

### Access Control

1. **VERIFY** user permissions before operations
2. **ESCALATE** when elevated privileges are needed
3. **DOCUMENT** access justification for sensitive operations
4. **REVIEW** access patterns for compliance
5. **ROTATE** API tokens according to security policy

### Data Handling

1. **CLASSIFY** data sensitivity levels appropriately
2. **APPLY** retention policies for investigation data
3. **SECURE** data transmission and storage
4. **ANONYMIZE** data when sharing outside team
5. **DELETE** temporary data after investigation completion

## Error Recovery & Resilience

### API Failures

1. **IMPLEMENT** circuit breaker patterns for repeated failures
2. **CACHE** successful responses to reduce API load
3. **GRACEFUL** degradation when tools are unavailable
4. **ALTERNATIVE** approaches when primary methods fail
5. **ESCALATION** procedures for persistent issues

### Data Quality

1. **VALIDATE** response data completeness
2. **CROSS-REFERENCE** data across multiple sources
3. **IDENTIFY** data anomalies and inconsistencies
4. **REPORT** data quality issues to administrators
5. **DOCUMENT** known data limitations

## Performance Optimization

### Query Efficiency

1. **MINIMIZE** number of API calls through intelligent batching
2. **OPTIMIZE** time ranges based on data freshness requirements
3. **PARALLELIZE** independent queries when possible
4. **CACHE** frequently accessed reference data
5. **MONITOR** query performance and adjust strategies

### Resource Management

1. **RESPECT** API rate limits and quotas
2. **QUEUE** non-urgent requests during peak times
3. **PRIORITIZE** critical monitoring over exploratory queries
4. **CLEAN UP** temporary resources and custom devices
5. **SCALE** operations based on system capacity

## User Experience Guidelines

### Response Quality

1. **PROVIDE** clear, actionable insights
2. **STRUCTURE** information logically and consistently
3. **HIGHLIGHT** critical issues requiring attention
4. **EXPLAIN** technical concepts in business terms
5. **OFFER** next steps and follow-up recommendations

### Error Communication

1. **EXPLAIN** errors in user-friendly language
2. **SUGGEST** specific corrective actions
3. **PROVIDE** alternative approaches when available
4. **ESCALATE** persistent issues appropriately
5. **DOCUMENT** common error patterns and solutions

Remember: These rules ensure secure, efficient, and responsible use of the Dynatrace Managed MCP server while protecting sensitive information, maintaining system stability, and providing valuable insights for monitoring and troubleshooting activities.
